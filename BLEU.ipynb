{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu9vi01Lfhx+3WZocsqDGb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/genarioazevedoufape/estudos_data_science/blob/main/BLEU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import math\n",
        "\n",
        "# Baixa recursos necessários do NLTK\n",
        "nltk.download('punkt')\n",
        "\n",
        "def normalizar_texto(texto):\n",
        "    \"\"\"Normaliza o texto convertendo para minúsculas e tokenizando.\"\"\"\n",
        "    return word_tokenize(texto.lower())\n",
        "\n",
        "def contar_ngramas(tokens, n):\n",
        "    \"\"\"Gera n-gramas e suas contagens a partir de uma lista de tokens.\"\"\"\n",
        "    return Counter(tuple(tokens[i:i+n]) for i in range(len(tokens) - n + 1))\n",
        "\n",
        "def precisao_modificada(candidato, referencias, n):\n",
        "    \"\"\"Calcula a precisão modificada de n-gramas para um candidato contra referências.\"\"\"\n",
        "    ngramas_candidato = contar_ngramas(candidato, n)\n",
        "    max_ngramas_referencia = Counter()\n",
        "\n",
        "    # Encontra a contagem máxima de cada n-grama entre todas as referências\n",
        "    for ref in referencias:\n",
        "        ngramas_ref = contar_ngramas(ref, n)\n",
        "        for ngrama in ngramas_ref:\n",
        "            max_ngramas_referencia[ngrama] = max(max_ngramas_referencia[ngrama], ngramas_ref[ngrama])\n",
        "\n",
        "    # Limita (clip) as contagens do candidato ao máximo das referências\n",
        "    contagens_clipadas = sum(min(ngramas_candidato[ngrama], max_ngramas_referencia[ngrama]) for ngrama in ngramas_candidato)\n",
        "    contagens_totais = sum(ngramas_candidato.values())\n",
        "\n",
        "    # Evita divisão por zero\n",
        "    return contagens_clipadas / contagens_totais if contagens_totais > 0 else 0.0\n",
        "\n",
        "def penalidade_brevidade(candidato, referencias):\n",
        "    \"\"\"Calcula a penalidade de brevidade com base no comprimento do candidato e da referência mais próxima.\"\"\"\n",
        "    c = len(candidato)\n",
        "    # Encontra o comprimento da referência mais próximo do candidato\n",
        "    r = min((len(ref) for ref in referencias), key=lambda x: abs(x - c))\n",
        "\n",
        "    if c >= r:\n",
        "        return 1.0\n",
        "    return math.exp(1 - r / c)\n",
        "\n",
        "def escore_bleu(candidato, referencias, max_n=4, pesos=None):\n",
        "    \"\"\"Calcula o escore BLEU para um candidato contra múltiplas referências.\"\"\"\n",
        "    if pesos is None:\n",
        "        pesos = [1.0 / max_n] * max_n\n",
        "\n",
        "    # Normaliza os textos\n",
        "    candidato = normalizar_texto(candidato)\n",
        "    referencias = [normalizar_texto(ref) for ref in referencias]\n",
        "\n",
        "    # Calcula as precisões modificadas para n-gramas\n",
        "    precisoes = []\n",
        "    for n in range(1, max_n + 1):\n",
        "        p_n = precisao_modificada(candidato, referencias, n)\n",
        "        precisoes.append(p_n)\n",
        "\n",
        "    # Aplica suavização para evitar precisões zero (adiciona pequeno epsilon)\n",
        "    precisoes = [p if p > 0 else 1e-16 for p in precisoes]\n",
        "\n",
        "    # Média geométrica das precisões\n",
        "    soma_log = sum(w * math.log(p) for w, p in zip(pesos, precisoes))\n",
        "    media_geometrica = math.exp(soma_log)\n",
        "\n",
        "    # Penalidade de brevidade\n",
        "    bp = penalidade_brevidade(candidato, referencias)\n",
        "\n",
        "    return bp * media_geometrica\n",
        "\n",
        "# Casos de teste para demonstrar o cálculo do escore BLEU\n",
        "def executar_testes_bleu():\n",
        "    \"\"\"Executa casos de teste para demonstrar o comportamento da métrica BLEU.\"\"\"\n",
        "    casos_teste = [\n",
        "        {\n",
        "            \"nome\": \"Correspondência Perfeita\",\n",
        "            \"candidato\": \"O gato está no tapete\",\n",
        "            \"referencias\": [\"O gato está no tapete\", \"Existe um gato no tapete\"],\n",
        "            \"descricao\": \"O candidato corresponde exatamente a uma referência.\"\n",
        "        },\n",
        "        {\n",
        "            \"nome\": \"Problema com Sinônimo\",\n",
        "            \"candidato\": \"O cão está no tapete\",\n",
        "            \"referencias\": [\"O gato está no tapete\", \"Existe um gato no tapete\"],\n",
        "            \"descricao\": \"O candidato usa 'cão' em vez de 'gato' (problema com sinônimo).\"\n",
        "        },\n",
        "        {\n",
        "            \"nome\": \"Diferença na Ordem das Palavras\",\n",
        "            \"candidato\": \"No tapete está o gato\",\n",
        "            \"referencias\": [\"O gato está no tapete\"],\n",
        "            \"descricao\": \"Mesmas palavras, mas ordem diferente afeta bigramas e superiores.\"\n",
        "        },\n",
        "        {\n",
        "            \"nome\": \"Tradução Truncada\",\n",
        "            \"candidato\": \"O gato\",\n",
        "            \"referencias\": [\"O gato está no tapete\", \"Existe um gato no tapete\"],\n",
        "            \"descricao\": \"Candidato curto ativa a penalidade de brevidade.\"\n",
        "        },\n",
        "        {\n",
        "            \"nome\": \"Candidato Repetitivo\",\n",
        "            \"candidato\": \"O o o\",\n",
        "            \"referencias\": [\"O gato está no tapete\"],\n",
        "            \"descricao\": \"Palavras repetitivas testam o clipping na precisão modificada.\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for teste in casos_teste:\n",
        "        escore = escore_bleu(teste[\"candidato\"], teste[\"referencias\"])\n",
        "        print(f\"\\nCaso de Teste: {teste['nome']}\")\n",
        "        print(f\"Descrição: {teste['descricao']}\")\n",
        "        print(f\"Candidato: {teste['candidato']}\")\n",
        "        print(f\"Referências: {teste['referencias']}\")\n",
        "        print(f\"Escore BLEU: {escore:.4f}\")\n",
        "\n",
        "        # Mostra as precisões individuais de n-gramas\n",
        "        tokens_candidato = normalizar_texto(teste[\"candidato\"])\n",
        "        tokens_referencias = [normalizar_texto(ref) for ref in teste[\"referencias\"]]\n",
        "        for n in range(1, 5):\n",
        "            p_n = precisao_modificada(tokens_candidato, tokens_referencias, n)\n",
        "            print(f\"Precisão (n={n}): {p_n:.4f}\")\n",
        "\n",
        "# Executa os testes quando o script é rodado\n",
        "if __name__ == \"__main__\":\n",
        "    executar_testes_bleu()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_seZ2Wgtvkh",
        "outputId": "f6952c49-b195-4f22-b6a6-651e5ab0655a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Caso de Teste: Correspondência Perfeita\n",
            "Descrição: O candidato corresponde exatamente a uma referência.\n",
            "Candidato: O gato está no tapete\n",
            "Referências: ['O gato está no tapete', 'Existe um gato no tapete']\n",
            "Escore BLEU: 1.0000\n",
            "Precisão (n=1): 1.0000\n",
            "Precisão (n=2): 1.0000\n",
            "Precisão (n=3): 1.0000\n",
            "Precisão (n=4): 1.0000\n",
            "\n",
            "Caso de Teste: Problema com Sinônimo\n",
            "Descrição: O candidato usa 'cão' em vez de 'gato' (problema com sinônimo).\n",
            "Candidato: O cão está no tapete\n",
            "Referências: ['O gato está no tapete', 'Existe um gato no tapete']\n",
            "Escore BLEU: 0.0001\n",
            "Precisão (n=1): 0.8000\n",
            "Precisão (n=2): 0.5000\n",
            "Precisão (n=3): 0.3333\n",
            "Precisão (n=4): 0.0000\n",
            "\n",
            "Caso de Teste: Diferença na Ordem das Palavras\n",
            "Descrição: Mesmas palavras, mas ordem diferente afeta bigramas e superiores.\n",
            "Candidato: No tapete está o gato\n",
            "Referências: ['O gato está no tapete']\n",
            "Escore BLEU: 0.0000\n",
            "Precisão (n=1): 1.0000\n",
            "Precisão (n=2): 0.5000\n",
            "Precisão (n=3): 0.0000\n",
            "Precisão (n=4): 0.0000\n",
            "\n",
            "Caso de Teste: Tradução Truncada\n",
            "Descrição: Candidato curto ativa a penalidade de brevidade.\n",
            "Candidato: O gato\n",
            "Referências: ['O gato está no tapete', 'Existe um gato no tapete']\n",
            "Escore BLEU: 0.0000\n",
            "Precisão (n=1): 1.0000\n",
            "Precisão (n=2): 1.0000\n",
            "Precisão (n=3): 0.0000\n",
            "Precisão (n=4): 0.0000\n",
            "\n",
            "Caso de Teste: Candidato Repetitivo\n",
            "Descrição: Palavras repetitivas testam o clipping na precisão modificada.\n",
            "Candidato: O o o\n",
            "Referências: ['O gato está no tapete']\n",
            "Escore BLEU: 0.0000\n",
            "Precisão (n=1): 0.3333\n",
            "Precisão (n=2): 0.0000\n",
            "Precisão (n=3): 0.0000\n",
            "Precisão (n=4): 0.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HbGCL4zWpqU0"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import collections\n",
        "from fractions import Fraction\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "def simple_tokenizer(text: str) -> List[str]:\n",
        "    \"\"\"Tokenizador simples que divide o texto em palavras e converte para minúsculas\"\"\"\n",
        "    return text.lower().split()\n",
        "\n",
        "def count_ngrams(tokens: List[str], n: int) -> Dict[Tuple[str, ...], int]:\n",
        "    \"\"\"Conta a ocorrência de n-gramas em uma lista de tokens\"\"\"\n",
        "    ngrams = collections.defaultdict(int)\n",
        "    for i in range(len(tokens) - n + 1):\n",
        "        ngram = tuple(tokens[i:i+n])\n",
        "        ngrams[ngram] += 1\n",
        "    return ngrams\n",
        "\n",
        "def modified_precision(candidate: List[str], references: List[List[str]], n: int) -> float:\n",
        "    \"\"\"Calcula a precisão modificada para n-gramas\"\"\"\n",
        "    candidate_ngrams = count_ngrams(candidate, n)\n",
        "    if not candidate_ngrams:\n",
        "        return 0.0\n",
        "\n",
        "    max_ref_ngrams = collections.defaultdict(int)\n",
        "    for ref in references:\n",
        "        ref_ngrams = count_ngrams(ref, n)\n",
        "        for ngram, count in ref_ngrams.items():\n",
        "            max_ref_ngrams[ngram] = max(max_ref_ngrams[ngram], count)\n",
        "\n",
        "    clipped_counts = 0\n",
        "    total_counts = 0\n",
        "\n",
        "    for ngram, count in candidate_ngrams.items():\n",
        "        clipped_counts += min(count, max_ref_ngrams.get(ngram, 0))\n",
        "        total_counts += count\n",
        "\n",
        "    return clipped_counts / total_counts if total_counts > 0 else 0.0\n",
        "\n",
        "def brevity_penalty(candidate: List[str], references: List[List[str]]) -> float:\n",
        "    \"\"\"Calcula a penalidade de brevidade\"\"\"\n",
        "    c = len(candidate)\n",
        "    ref_lens = [len(ref) for ref in references]\n",
        "    r = min(ref_lens, key=lambda x: abs(x - c))\n",
        "\n",
        "    if c > r:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return math.exp(1 - r / c) if c > 0 else 0.0\n",
        "\n",
        "def bleu_score(candidate: str, references: List[str], weights: List[float] = None, tokenizer=None) -> float:\n",
        "    \"\"\"Calcula o score BLEU para uma candidata e múltiplas referências\"\"\"\n",
        "    if weights is None:\n",
        "        weights = [0.25, 0.25, 0.25, 0.25]  # Padrão para BLEU-4\n",
        "\n",
        "    if tokenizer is None:\n",
        "        tokenizer = simple_tokenizer\n",
        "\n",
        "    # Tokeniza as sentenças\n",
        "    candidate_tokens = tokenizer(candidate)\n",
        "    reference_tokens = [tokenizer(ref) for ref in references]\n",
        "\n",
        "    # Calcula as precisões modificadas para cada n-grama\n",
        "    precisions = []\n",
        "    for i in range(len(weights)):\n",
        "        p = modified_precision(candidate_tokens, reference_tokens, i+1)\n",
        "        precisions.append(p)\n",
        "\n",
        "    # Calcula a penalidade de brevidade\n",
        "    bp = brevity_penalty(candidate_tokens, reference_tokens)\n",
        "\n",
        "    # Calcula a média geométrica ponderada das precisões\n",
        "    sum_log_p = 0.0\n",
        "    for w, p in zip(weights, precisions):\n",
        "        if p > 0:\n",
        "            sum_log_p += w * math.log(p)\n",
        "        else:\n",
        "            # Se qualquer precisão for zero, o BLEU será zero\n",
        "            return 0.0\n",
        "\n",
        "    # Calcula o score final\n",
        "    bleu = bp * math.exp(sum_log_p)\n",
        "    return bleu\n",
        "\n",
        "def corpus_bleu(candidates: List[str], references: List[List[str]], weights: List[float] = None, tokenizer=None) -> float:\n",
        "    \"\"\"Calcula o BLEU para um corpus inteiro (múltiplas sentenças)\"\"\"\n",
        "    if weights is None:\n",
        "        weights = [0.25, 0.25, 0.25, 0.25]\n",
        "\n",
        "    if tokenizer is None:\n",
        "        tokenizer = simple_tokenizer\n",
        "\n",
        "    # Calcula BLEU para cada par candidato-referência\n",
        "    individual_scores = []\n",
        "    for cand, refs in zip(candidates, references):\n",
        "        score = bleu_score(cand, refs, weights, tokenizer)\n",
        "        individual_scores.append(score)\n",
        "\n",
        "    # Retorna a média dos scores individuais\n",
        "    return sum(individual_scores) / len(individual_scores) if individual_scores else 0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo 1: Tradução perfeita\n",
        "ref1 = \"o gato está no tapete\"\n",
        "cand1 = \"o gato está no tapete\"\n",
        "print(f\"Exemplo 1 - BLEU: {bleu_score(cand1, [ref1])}\")  # Deve ser 1.0\n",
        "\n",
        "# Exemplo 2: Tradução com ordem invertida\n",
        "ref2 = \"o gato persegue o rato\"\n",
        "cand2 = \"o rato persegue o gato\"\n",
        "print(f\"Exemplo 2 - BLEU: {bleu_score(cand2, [ref2])}\")  # Deve ser 0.0 (devido aos bigramas)\n",
        "\n",
        "# Exemplo 3: Tradução muito curta\n",
        "ref3 = \"o gato está sobre o tapete\"\n",
        "cand3 = \"o gato\"\n",
        "print(f\"Exemplo 3 - BLEU: {bleu_score(cand3, [ref3])}\")  # Deve ser baixo devido à penalidade de brevidade\n",
        "\n",
        "# Exemplo 4: Tradução com repetição\n",
        "ref4 = \"o gato está no tapete\"\n",
        "cand4 = \"o o o o o\"\n",
        "print(f\"Exemplo 4 - BLEU: {bleu_score(cand4, [ref4])}\")  # Deve ser 0.0\n",
        "\n",
        "# Exemplo 5: Múltiplas referências\n",
        "refs5 = [\"o gato está no tapete\", \"há um gato no tapete\"]\n",
        "cand5 = \"o gato está sobre o tapete\"\n",
        "print(f\"Exemplo 5 - BLEU: {bleu_score(cand5, refs5)}\")  # Deve ser entre 0 e 1\n",
        "\n",
        "# Exemplo 6: Corpus completo\n",
        "corpus_candidates = [\n",
        "    \"o gato está no tapete\",\n",
        "    \"o cachorro late\",\n",
        "    \"o pássaro canta\"\n",
        "]\n",
        "corpus_references = [\n",
        "    [\"o gato está no tapete\", \"há um gato no tapete\"],\n",
        "    [\"o cão late\", \"o cachorro faz au au\"],\n",
        "    [\"a ave canta\", \"o pássaro está cantando\"]\n",
        "]\n",
        "print(f\"Exemplo 6 - Corpus BLEU: {corpus_bleu(corpus_candidates, corpus_references)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3QyjZo-p9YG",
        "outputId": "88ac15d5-1f50-4dfc-9eec-01c0b2958bff"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exemplo 1 - BLEU: 1.0\n",
            "Exemplo 2 - BLEU: 0.0\n",
            "Exemplo 3 - BLEU: 0.0\n",
            "Exemplo 4 - BLEU: 0.0\n",
            "Exemplo 5 - BLEU: 0.0\n",
            "Exemplo 6 - Corpus BLEU: 0.3333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z20SQEzTqOi9",
        "outputId": "876b7189-49a2-4b14-ccd8-63e20c79ddc0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Ensure the 'punkt_tab' resource is downloaded\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('punkt') # Keep the existing download as well\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu as nltk_corpus_bleu\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Função para tokenizar com NLTK\n",
        "def nltk_tokenizer(text):\n",
        "    return word_tokenize(text.lower())\n",
        "\n",
        "# Testando com NLTK\n",
        "print(\"\\nComparação com NLTK:\")\n",
        "print(f\"Nossa implementação: {bleu_score(cand1, [ref1], tokenizer=nltk_tokenizer)}\")\n",
        "print(f\"NLTK: {sentence_bleu([nltk_tokenizer(ref1)], nltk_tokenizer(cand1))}\")\n",
        "\n",
        "# Testando corpus BLEU\n",
        "print(\"\\nCorpus BLEU - Nossa implementação:\", corpus_bleu(corpus_candidates, corpus_references, tokenizer=nltk_tokenizer))\n",
        "print(\"Corpus BLEU - NLTK:\", nltk_corpus_bleu([[nltk_tokenizer(r) for r in refs] for refs in corpus_references],\n",
        "                                             [nltk_tokenizer(c) for c in corpus_candidates]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvhVE8fbqHhl",
        "outputId": "ae7e433d-40d8-420b-aeb7-eeba596af93c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparação com NLTK:\n",
            "Nossa implementação: 1.0\n",
            "NLTK: 1.0\n",
            "\n",
            "Corpus BLEU - Nossa implementação: 0.3333333333333333\n",
            "Corpus BLEU - NLTK: 0.6887246539984299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Teste com sinônimos\n",
        "ref_syn = \"o cachorro está no tapete\"\n",
        "cand_syn = \"o cão está no tapete\"\n",
        "print(f\"\\nTeste com sinônimos - BLEU: {bleu_score(cand_syn, [ref_syn])}\")  # Será baixo pois BLEU não reconhece sinônimos\n",
        "\n",
        "# Teste com sentença mais longa que a referência\n",
        "ref_long = \"o gato está no tapete\"\n",
        "cand_long = \"o gato preto está deitado no tapete azul\"\n",
        "print(f\"Teste com sentença longa - BLEU: {bleu_score(cand_long, [ref_long])}\")  # Não há penalidade por ser mais longa\n",
        "\n",
        "# Teste com smoothing (para evitar zeros)\n",
        "def smoothed_bleu(candidate, references, weights=None, tokenizer=None): # Add tokenizer parameter\n",
        "    if weights is None:\n",
        "        weights = [0.25, 0.25, 0.25, 0.25]\n",
        "\n",
        "    if tokenizer is None: # Add default tokenizer\n",
        "        tokenizer = simple_tokenizer\n",
        "\n",
        "    # Aplica um pequeno smoothing para evitar log(0)\n",
        "    precisions = []\n",
        "    for i in range(len(weights)):\n",
        "        p = modified_precision(tokenizer(candidate), [tokenizer(ref) for ref in references], i+1)\n",
        "        precisions.append(p + 1e-10)  # Smoothing\n",
        "\n",
        "    bp = brevity_penalty(tokenizer(candidate), [tokenizer(ref) for ref in references])\n",
        "    sum_log_p = sum(w * math.log(p) for w, p in zip(weights, precisions))\n",
        "    return bp * math.exp(sum_log_p)\n",
        "\n",
        "print(f\"Teste com smoothing - BLEU: {smoothed_bleu(cand2, [ref2])}\")  # Agora não será zero absoluto"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9GcqMXiqX3w",
        "outputId": "77b4686a-4da6-416b-9fdf-356f06619ca1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Teste com sinônimos - BLEU: 0.0\n",
            "Teste com sentença longa - BLEU: 0.0\n",
            "Teste com smoothing - BLEU: 9.306048591563838e-06\n"
          ]
        }
      ]
    }
  ]
}